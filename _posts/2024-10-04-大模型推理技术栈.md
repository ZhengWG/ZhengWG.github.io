---
layout: post
title: 大模型推理技术栈
date: 2024-10-04 20:00:00.000000000 +09:00
categories: [算法部署]
tags: [模型部署, LLM]
---

## 前言

影响LLM推理性能的因素有很多，包括但是不限于：模型配置、硬件类型、数据分布、优化算法、推理策略等。本位旨在综述各类技术点，后续会针对核心技术做详细展开。

![image-20241220130643718](https://cdn.jsdelivr.net/gh/ZhengWG/Imgs_blog//2024-12-19-LLM%25E6%258E%25A8%25E7%2590%2586%25E6%258A%2580%25E6%259C%25AF%25E6%25A0%2588_new/image-20241220130643718.png){: .img-mid }

## 算法

### LLM

#### 参数建模

[大模型计算建模](https://johneyzheng.top/posts/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%AE%A1%E7%AE%97%E5%BB%BA%E6%A8%A1/)

#### Transformer

[FlashAttention系列优化](https://johneyzheng.top/posts/FlashAttention%E7%B3%BB%E5%88%97%E4%BC%98%E5%8C%96/)

[MoEs算法&&部署概述](http://johneyzheng.top/posts/MoEs%E7%AE%97%E6%B3%95&&%E9%83%A8%E7%BD%B2%E6%A6%82%E8%BF%B0/)

### 量化

[LLMs量化算法概述](http://johneyzheng.top/posts/LLMs%E9%87%8F%E5%8C%96%E7%AE%97%E6%B3%95%E6%A6%82%E8%BF%B0/)

## 框架

开源的LLM推理框架有TensorRT-LLM、FasterTransformer、TGI、vLLM、NanoFlow、SGLANG等，以VLLM为例简单介绍下推理框架：

 ![img](https://cdn.jsdelivr.net/gh/ZhengWG/Imgs_blog//2024-12-19-LLM%25E6%258E%25A8%25E7%2590%2586%25E6%258A%2580%25E6%259C%25AF%25E6%25A0%2588_new/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86%E6%8A%80%E6%9C%AF%E6%A0%88_20240917_003702.png){: .img-mid } 

### Serving策略

[Orca-Continuous Batching策略](https://johneyzheng.top/posts/Orca-Continuous_Batching%E7%AD%96%E7%95%A5/)

[SGLang-Prefix Prompt Cache设计](https://johneyzheng.top/posts/SGLang-Prefix_Prompt_Cache%E8%AE%BE%E8%AE%A1/)

[Lora&&Multi-Lora](http://johneyzheng.top/posts/Lora&&Multi-Lora/)

[Prefill Decode分离部署](https://johneyzheng.top/posts/Prefill_Decode%E5%88%86%E7%A6%BB%E9%83%A8%E7%BD%B2/)

[RLHF算法以及部署概述](https://johneyzheng.top/posts/RLHF%E7%AE%97%E6%B3%95%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%A6%82%E8%BF%B0/)

### Engine部署

[PP&&TP LLMs部署](https://johneyzheng.top/posts/PP&&TP_LLMs%E9%83%A8%E7%BD%B2/)

[LLMs图编译概述](http://johneyzheng.top/posts/LLMs%E5%9B%BE%E7%BC%96%E8%AF%91%E6%A6%82%E8%BF%B0/)

### 高性能算子

#### 软件栈

[算子编程模型](http://johneyzheng.top/posts/%E7%AE%97%E5%AD%90%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B/)

#### 算子优化

[GEMM算子优化](http://johneyzheng.top/posts/GEMM%E7%AE%97%E5%AD%90%E4%BC%98%E5%8C%96/)

[FlashAttention系列优化](https://johneyzheng.top/posts/FlashAttention%E7%B3%BB%E5%88%97%E4%BC%98%E5%8C%96/)

## 中间件（TODO）

## 硬件系统

### 计算

[AI模型部署硬件综述](https://johneyzheng.top/posts/AI%E6%A8%A1%E5%9E%8B%E9%83%A8%E7%BD%B2%E7%A1%AC%E4%BB%B6%E7%BB%BC%E8%BF%B0/)

### 存储（TODO）

### 通信（TODO）

## 场景优化

[LLM长文本优化策略](http://johneyzheng.top/posts/LLM%E9%95%BF%E6%96%87%E6%9C%AC%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/)

## 参考资料

[揭秘 LLM 推理：全面解析 LLM 推理性能的关键因素](https://mp.weixin.qq.com/s/RoWK5au-8Pr-_MJZ3P34xw)

[投机采样](https://zhuanlan.zhihu.com/p/651359908)

[Continuos——Batching](https://zhuanlan.zhihu.com/p/688551989)

[Qlora/GPTQ量化概述](https://zhuanlan.zhihu.com/p/646210009)

[LLM推理部署 - 量化（llm.int8，AWQ，GPTQ，SMOOTHQUANT）](https://zhuanlan.zhihu.com/p/690853855)

[谈谈对OpenAI Triton的一些理解](https://zhuanlan.zhihu.com/p/613244988)

[CUTLASS:Fast Linear Algebra in CUDA C++](https://zhuanlan.zhihu.com/p/461060382)

[一文搞懂TorchDynamo原理](https://zhuanlan.zhihu.com/p/630933479)

[混合专家模型(MoE)详解](https://huggingface.co/blog/zh/moe#%E6%B7%B7%E5%90%88%E4%B8%93%E5%AE%B6%E6%A8%A1%E5%9E%8B%E4%B8%AD%E4%BB%A4%E7%89%8C%E7%9A%84%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1)

[LLM学习笔记-Deepspeed-MoE论文](https://www.cnblogs.com/marsggbo/p/17883514.html)

[大模型训练之序列并行双雄：DeepSpeed Ulysses & Ring-Attention](https://zhuanlan.zhihu.com/p/689067888)

[更适合flash attention体质的上下文训练方案](https://zhuanlan.zhihu.com/p/718486708)

[GPU工作原理解析](https://zhuanlan.zhihu.com/p/697694330)

[从现代GPU编程角度看SIMD与SIMT](https://zhuanlan.zhihu.com/p/113360369#:~:text=%E4%BB%8E%E6%88%91%E7%9A%84%E7%A0%94%E7%A9%B6%E7%9C%8B%EF%BC%8CSIM)

[x64 CPU GEMM优化](https://zhuanlan.zhihu.com/p/593537184#:~:text=%E5%9C%A8%20%E3%80%8A%E7%8E%A9%E8%BD%ACSIMD%E6%8C%87%E4%BB%A4%E7%BC%96%E7%A8%8B%E3%80%8B%20%E4%B8%80%E6%96%87%E4%B8%AD%EF%BC%8C%E4%BB%8B%E7%BB%8D%E4%BA%86SIMD%E7%9A%84%E6%A6%82%E5%BF%B5%E5%92%8C%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95%EF%BC%8C%E4%B9%9F%E9%80%9A%E8%BF%87)

[CUTLASS: Efficient GEMM in CUDA](https://blog.csdn.net/yiran103/article/details/132216620#:~:text=%E5%9F%BA%E6%9C%AC%E7%9A%84%E4%B8%89%E9%87%8D%E5%B5%8C%E5%A5%97%E5%BE%AA%E7%8E%AF%E8%AE%A1)

[深入浅出GPU优化系列：GEMM优化(一)](https://zhuanlan.zhihu.com/p/435908830#:~:text=%E6%9C%AC%E7%AF%87%E6%96%87%E7%AB%A0%E6%98%AF%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAG)

[FlashAttention2详解（性能比FlashAttention提升20%）](https://zhuanlan.zhihu.com/p/645376942#:~:text=%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E6%98%BE%E7%A4%BA%EF%BC%8CFla)
